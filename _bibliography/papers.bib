---
---








@article{hao2025mimo,
  abbr={Technical Report},
  title={MiMo-Embodied: X-Embodied Foundation Model Technical Report},
  author={Hao*, Xiaoshuai and Zhou*, Lei and Huang*, Zhijian and Hou*, Zhiwen and Tang*, Yingbo and Zhang*, Lingfeng and Li*, Guang and Lu*, Zheng and Ren, Shuhuai and Meng, Xianhui and others},
  journal={arXiv preprint arXiv:2511.16518},
  year={2025},
  selected={true},
  code={https://github.com/XiaomiMiMo/MiMo-Embodied},
  arxiv={https://arxiv.org/pdf/2511.16518},
  preview={mimo.png},
  annotation={* Core Contributors.}
}

@article{zhang2025your,
  abbr={Under Review},
  title={Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation},
  author={Zhang*, Lingfeng and Zhang*, Yuchen and Li, Hongsheng and Fu, Haoxiang and Tang, Yingbo and Ye, Hangjun and Chen, Long and Liang, Xiaojun and Hao, Xiaoshuai and Ding‚Ä†, Wenbo},
  journal={arXiv preprint arXiv:2511.13269},
  year={2025},
  selected={true},
  code={https://github.com/linglingxiansen/SpatialSKy},
  arxiv={https://arxiv.org/pdf/2511.13269},
  preview={sky.png},
  annotation={* Co-first authors.}
}

@article{zhang2025socialnav,
  abbr={Under Review},
  title={SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation},
  author={Zhang, Lingfeng and Xiao, Erjia and Hao, Xiaoshuai and Fu, Haoxiang and Gong, Zeying and Chen, Long and Liang, Xiaojun and Xu, Renjing and Ye, Hangjun and Ding, Wenbo},
  journal={arXiv preprint arXiv:2511.12232},
  year={2025},
  code={https://github.com/linglingxiansen/SocialNav-Map},
  arxiv={https://arxiv.org/pdf/2511.12232},
  preview={socialnav.png}
}




@article{zhang2026what,
  abbr={AAAI},
  title={What You See is What You Reach: Towards Spatial Navigation with High-Level Human Instructions},
  author={Zhang*, Lingfeng and Fu*, Haoxiang and Hao, Xiaoshuai and Zhang, Shuyi and Zhang, Qiang and Liu, Rui and Chen, Long and Ding‚Ä†, Wenbo},
  journal={},
  year={2026},
  selected={true},
  code={},
  arxiv={},
  preview={spatialnav.png},
  annotation={* Co-first authors.}
}

@article{hao2025roboafford++,
  abbr={üèÜBest Paper Award},
  title={RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation},
  author={Hao, Xiaoshuai and Tang, Yingbo and Zhang, Lingfeng and Ma, Yanbiao and Diao, Yunfeng and Jia, Ziyu and Ding, Wenbo and Ye, Hangjun and Chen, Long},
  journal={arXiv preprint arXiv:2511.12436},
  year={2025},
  selected={true},
  code={https://github.com/tyb197/RoboAfford},
  arxiv={https://arxiv.org/pdf/2511.12436},
  award={Best Paper and Best Poster Award at IROS 2025 RoDGE Workshop},
  award_name={Best Paper Award}, 
  preview={roboafford++.png}
}


@article{cheng2025exploring,
  abbr={üèÜBest Student Paper Award},
  title={Exploring typographic visual prompts injection threats in cross-modality generation models},
  author={Cheng, Hao and Xiao, Erjia and Wang, Yichi and Zhang, Lingfeng and Zhang, Qiang and Cao, Jiahang and Xu, Kaidi and Sun, Mengshu and Hao, Xiaoshuai and Gu, Jindong and others},
  journal={arXiv preprint arXiv:2503.11519},
  year={2025},
  selected={true},
  code={https://github.com/ChaduCheng/Typographic-Visual-Prompts-Injection},
  arxiv={https://arxiv.org/pdf/2503.11519},
  award={Best Student Paper at IJCAI Workshop on Deepfake Detection, Localization and Interpretability},
  award_name={Best Student Paper Award}, 
  preview={ijcai.png}
}



@inproceedings{tang2025roboafford,
  abbr={ACM MM},
  title={Roboafford: A dataset and benchmark for enhancing object and spatial affordance learning in robot manipulation},
  author={Tang*, Yingbo and Zhang*, Lingfeng and Zhang, Shuyi and Zhao, Yinuo and Hao, Xiaoshuai},
  booktitle={Proceedings of the 33rd ACM International Conference on Multimedia},
  pages={12706--12713},
  year={2025},
  selected={true},
  code={https://github.com/tyb197/RoboAfford},
  pdf={https://dl.acm.org/doi/pdf/10.1145/3746027.3758209},
  preview={roboafford.png},
  annotation={* Co-first authors.}
}


@inproceedings{zhang2025video,
  abbr={ACM MM},
  title={Video-cot: A comprehensive dataset for spatiotemporal understanding of videos based on chain-of-thought},
  author={Zhang, Shuyi and Hao, Xiaoshuai and Tang, Yingbo and Zhang, Lingfeng and Wang, Pengwei and Wang, Zhongyuan and Ma, Hongxuan and Zhang, Shanghang},
  booktitle={Proceedings of the 33rd ACM International Conference on Multimedia},
  pages={12745--12752},
  year={2025},
  code={https://huggingface.co/datasets/Zooy138/Video-CoT},
  pdf={https://dl.acm.org/doi/pdf/10.1145/3746027.3758313},
  preview={videocot.png}
}


@article{zhang2025nava,
  abbr={Under Review},
  title={$NavA^{3}$: Understanding Any Instruction, Navigating Anywhere, Finding Anything},
  author={Zhang*, Lingfeng and Hao*, Xiaoshuai and Tang, Yingbo and Fu, Haoxiang and Zheng, Xinyu and Wang, Pengwei and Wang, Zhongyuan and Ding‚Ä†, Wenbo and Zhang‚Ä†, Shanghang},
  journal={arXiv preprint arXiv:2508.04598},
  year={2025},
  selected={true},
  code={https://github.com/linglingxiansen/NavA3},
  arxiv={https://arxiv.org/pdf/2508.04598},
  preview={nava.png},
  annotation={* Co-first authors.}
}

@article{team2025robobrain,
  abbr={Technical Report},
  title={Robobrain 2.0 technical report},
  author={Team, BAAI RoboBrain and Cao, Mingyu and Tan, Huajie and Ji, Yuheng and Chen, Xiansheng and Lin, Minglan and Li, Zhiyu and Cao, Zhou and Wang, Pengwei and Zhou, Enshen and others},
  journal={arXiv preprint arXiv:2507.02029},
  year={2025},
  selected={true},
  code={https://github.com/FlagOpen/RoboBrain2.0},
  arxiv={https://arxiv.org/pdf/2507.02029},
  preview={robobrain.png}
}

@inproceedings{zhang2025mapnav,
  abbr={ACL},
  title={Mapnav: A novel memory representation via annotated semantic maps for vlm-based vision-and-language navigation},
  author={Zhang*, Lingfeng and Hao*, Xiaoshuai and Xu, Qinwen and Zhang, Qiang and Zhang, Xinyao and Wang, Pengwei and Zhang, Jing and Wang, Zhongyuan and Zhang‚Ä†, Shanghang and Xu‚Ä†, Renjing},
  booktitle={The 63rd Annual Meeting of the Association for Computational Linguistics},
  year={2025},
  selected={true},
  code={https://github.com/linglingxiansen/MapNav},
  arxiv={https://arxiv.org/pdf/2502.13451},
  preview={mapnav.png},
  annotation={* Co-first authors.}
}


@inproceedings{zhang2025multi,
  abbr={ICRA},
  title={Multi-floor zero-shot object navigation policy},
  author={Zhang*, Lingfeng and Wang*, Hao and Xiao*, Erjia and Zhang, Xinyao and Zhang, Qiang and Jiang, Zixuan and Xu‚Ä†, Renjing},
  booktitle={2025 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6416--6422},
  year={2025},
  organization={IEEE},
  doi={10.1109/ICRA55743.2025.11128607},
  annotation={* Co-first authors.},
  code={https://github.com/linglingxiansen/TriHelper},
  arxiv={https://arxiv.org/pdf/2409.10906},
  preview={mfnp.png},
  annotation={* Co-first authors.}
}

@inproceedings{zhang2024trihelper,
  abbr={IROS},
  title={Trihelper: Zero-shot object navigation with dynamic assistance},
  author={Zhang, Lingfeng and Zhang, Qiang and Wang, Hao and Xiao, Erjia and Jiang, Zixuan and Chen, Honglei and Xu‚Ä†, Renjing},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={10035--10042},
  year={2024},
  organization={IEEE},
  code={https://github.com/linglingxiansen/TriHelper},
  arxiv={https://arxiv.org/pdf/2403.15223},
  preview={trihelper.png}
}





@inproceedings{fang2024spiking,
  abbr={ECCV},
  title={Spiking wavelet transformer},
  author={Fang, Yuetong and Wang, Ziqing and Zhang, Lingfeng and Cao, Jiahang and Chen, Honglei and Xu, Renjing},
  booktitle={European conference on computer vision},
  pages={19--37},
  year={2024},
  organization={Springer},
  code={https://github.com/bic-L/Spiking-Wavelet-Transformer},
  arxiv={https://arxiv.org/pdf/2403.11138},
  preview={swt.png}
}